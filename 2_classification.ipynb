{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides many helper functions to download popular datasets. MNIST (\"Modified National Institute of Standards and Technology\") is one of them. The MNIST database is a large database of handwritten digits that is commonly used for training various image processing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image is 28×28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to do is grab an instance’s feature vector, reshape it to a 28×28 array, and display it using Matplotlib’s imshow() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106a5a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to use some other index like 26000\n",
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "\n",
    "#Try to switch off the axis\n",
    "#plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always create a test set and set it aside before inspecting the data closely. The MNIST dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "\n",
    "#Try to split test and train data by 65000, or 69000 and observe the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also shuffle the training set; this will guarantee that all cross-validation folds will be similar (you don’t want one fold to be missing some digits). Moreover, some learning algorithms are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row. Shuffling the dataset ensures that this won’t happen:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "\n",
    "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. This “5-detector” will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)  # True for all 5s, False for all other digits.\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "#Try to model for all 4s or 2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let’s pick a classifier and train it. A good place to start is with a Stochastic Gradient Descent (SGD) classifier, using Scikit-Learn’s SGDClassifier class. This classifier has the advantage of being capable of handling very large datasets efficiently. This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning)\n",
    "\n",
    "Difference between batch and SGD:\n",
    "https://stats.stackexchange.com/questions/49528/batch-gradient-descent-versus-stochastic-gradient-descent\n",
    "https://towardsdatascience.com/difference-between-batch-gradient-descent-and-stochastic-gradient-descent-1187f1291aa1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=100, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Try changing max_iter to 25, 50, 75, 125 and observe execution time and accuracy\n",
    "\n",
    "sgd_clf = SGDClassifier( max_iter=100, tol=None)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use it to detect images of the number 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Accuracy Using Cross-Validation\n",
    "\n",
    "A good way to evaluate a model is to use cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96585,  0.96505,  0.96635])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# Try with cv=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5th row and 3rd column of the confusion matrix.\n",
    "\n",
    "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch). Instead, you can use the cross_val_predict() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training).\n",
    "\n",
    "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53726,   853],\n",
       "       [ 1150,  4271]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## see if we assign training data to predicted values\n",
    "# y_train_perfect_predictions = y_train_5\n",
    "# confusion_matrix(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 54,174 of them were correctly classified as non-5s (they are called true negatives), while the remaining 405 were wrongly classified as 5s (false positives). The second row considers the images of 5s (the positive class): 1,931 were wrongly classified as non-5s (false negatives), while the remaining 3,490 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83352849336455892"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78786201807784539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846820809248555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)\n",
    "0.78468208092485547"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Links:\n",
    "* https://machinelearningmastery.com/confusion-matrix-machine-learning/\n",
    "* https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
